{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from sacrebleu.metrics import BLEU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "original = pd.read_csv(\"cleaned_snopes.csv\", sep=\"|\")\n",
    "back_translated_TA = pd.read_csv(\"snopes_backtranslation_ta_IN-en_XX.csv\")\n",
    "back_translated_VI = pd.read_csv(\"snopes_backtranslation_vi_VN-en_XX.csv\")\n",
    "back_translated_XH = pd.read_csv(\"snopes_backtranslation_xh_ZA-en_XX.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   label                                              claim\n",
      "0  False  A man claiming to be transgender allegedly ass...\n",
      "1  False  An aide handed Sean Spicer a note that read “Y...\n",
      "2  False  Hip-hop and pop star Nelly was arrested on dru...\n",
      "3  False  President Obama pardoned Chelsea Manning and 1...\n",
      "4   True               No two snowflakes are exactly alike.\n",
      "   label                                              claim\n",
      "0  False  A young woman is said to have been attacked in...\n",
      "1  False  An aide, Sean Spicer, gave a note in which it ...\n",
      "2  False  He was arrested on drug charges while on a tri...\n",
      "3  False  President Obama pardoned Chelsea Manning and 1...\n",
      "4   True                The two ice cubes are not the same.\n"
     ]
    }
   ],
   "source": [
    "print(original.head())\n",
    "print(back_translated_TA.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = [original[\"claim\"].to_numpy().tolist()]\n",
    "h_TA = back_translated_TA[\"claim\"].to_numpy().tolist()\n",
    "h_VI = back_translated_VI[\"claim\"].to_numpy().tolist()\n",
    "h_XH = back_translated_XH[\"claim\"].to_numpy().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "bleu = BLEU()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU = 31.35 63.0/38.3/25.4/17.3 (BP = 0.977 ratio = 0.978 hyp_len = 78361 ref_len = 80156)\n",
      "BLEU = 38.16 67.5/44.7/31.3/22.5 (BP = 1.000 ratio = 1.016 hyp_len = 81477 ref_len = 80156)\n",
      "BLEU = 25.52 52.2/32.5/23.8/18.8 (BP = 0.864 ratio = 0.873 hyp_len = 69955 ref_len = 80156)\n"
     ]
    }
   ],
   "source": [
    "bleu_score_TA = bleu.corpus_score(h_TA, t1)\n",
    "bleu_score_VI = bleu.corpus_score(h_VI, t1)\n",
    "bleu_score_XH = bleu.corpus_score(h_XH, t1)\n",
    "\n",
    "print(bleu_score_TA)\n",
    "print(bleu_score_VI)\n",
    "print(bleu_score_XH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac6e2c3646ad462fae80473fd514929d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e67721638e6e49fa8889b0459b7c2d03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)080f75ec7e72/LICENSE:   0%|          | 0.00/9.69k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "925ad71529a54abc8c8bfd06068c3bca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)c7e72/.gitattributes:   0%|          | 0.00/1.48k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1b5e90924d24bb3811423efaebddae3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)0f75ec7e72/README.md:   0%|          | 0.00/3.53k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f696f1e7359746ca8c375344f2902a7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)5ec7e72/hparams.yaml:   0%|          | 0.00/567 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea0e6582c2144aa982f1dcc9f3f468e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)\"model.ckpt\";:   0%|          | 0.00/2.32G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.8.3.post1 to v1.9.5. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint --file ../.cache/huggingface/hub/models--Unbabel--wmt22-comet-da/snapshots/371e9839ca4e213dde891b066cf3080f75ec7e72/checkpoints/model.ckpt`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e9cddcd4d044fdd93a17e3a732c2443",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)tencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "484b4185897947af9840f757f8568e04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/9.10M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca8b281478a84b38a10e32a42a1785f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/616 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoder model frozen.\n"
     ]
    }
   ],
   "source": [
    "from comet import download_model, load_from_checkpoint\n",
    "\n",
    "model_path = download_model(\"Unbabel/wmt22-comet-da\")\n",
    "if not 'model' in globals():\n",
    "  model = load_from_checkpoint(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "translation_TA = pd.read_csv(\"snopes_ta_IN.csv\")\n",
    "translation_TA = translation_TA[\"claim\"]\n",
    "translation_VI = pd.read_csv(\"snopes_vi_VN.csv\")\n",
    "translation_VI = translation_VI[\"claim\"]\n",
    "translation_XH = pd.read_csv(\"snopes_xh_ZA.csv\")\n",
    "translation_XH = translation_XH[\"claim\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_data(eng_orig, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_TA = []\n",
    "\n",
    "for "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_scores, sys_score = model.predict(data, batch_size=1, gpus=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
